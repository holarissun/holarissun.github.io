---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

  My full publication list can be found on <u><a href="https://scholar.google.com/citations?user=7ZNoHJkAAAAJ&hl=en">my Google Scholar profile</a>.</u>

<!-- {% include base_path %} -->
<!-- *: corresponding author -->


## Conference
### [NeurIPS 2022] Exploiting Reward Shifting in Value-Based DRL  <a href="https://arxiv.org/abs/2209.07288"> [Paper] </a><a href="https://github.com/2Groza/RewardShifting"> [Code] </a>

*Hao Sun, Lei Han, Rui Yang, Xiaoteng Ma, Jian Guo, Bolei Zhou*

- A positive reward shifting leads to conservative exploitation, while a negative reward shifting leads to curiosity-driven exploration.


### [ICLR 2022] Rethinking Goal-conditioned Supervised Learning and Its Connection to Offline RL <a href="https://arxiv.org/abs/2202.04478"> [Paper] </a><a href="https://github.com/YangRui2015/AWGCSL"> [Code] </a>

*Rui Yang, Yiming Lu, Wenzhe Li, Hao Sun, Meng Fang, Yali Du, Xiu Li, Lei Han, Chongjie Zhang*
- We optimize the GCSL with a lower bound of the goal-reaching objective and link the success of GCSL from perspective of offline RL.

### [IJCAI 2021] Hierarchical Multi-Scale Gaussian Transformer for Stock Movement Prediction <a href="https://www.ijcai.org/proceedings/2020/0640.pdf"> [Paper] </a>

*Qianggang Ding, Sifan Wu, Hao Sun, Jiadong Guo, Jian Guo*

- We adapt transformer to stock movement predictions.

### [AAAI 2021] Adaptive Regularization of Labels <a href="https://arxiv.org/abs/1908.05474"> [Paper] </a>

*Qianggang Ding, Sifan Wu, Hao Sun, Jiadong Guo, Shu-Tao Xia*
- We study the correlations between lables to improve model performance.


### [NeurIPS 2019 (Spotlight)] Policy Continuation with Hindsight Inverse Dynamics <a href="https://arxiv.org/abs/1910.14055"> [Paper] </a><a href="https://github.com/2Groza/PCHID_code"> [Code] </a> <a href='https://sites.google.com/view/neurips2019pchid/'> [Homepage] </a>

*Hao Sun, Zhizhong Li, Xiaotong Liu, Dahua Lin, Bolei Zhou*
- Supervised Learning can be used to solve goal-conditioned RL tasks.


## Workshop

### [ICML 2022 DFUQ] DAUX: a Density-based Approach for Uncertainty eXplanations <a href="https://arxiv.org/abs/2207.05161"> [Paper] </a><a href="https://anonymous.4open.science/r/DAUX-CBBF"> [Code] </a>

*Hao Sun^, Boris van Breugel^, Jonathan Crabbe, Nabeel Seedat, Mihaela van der Schaar*
- We propose a density-based approach to classify uncertain examples.
